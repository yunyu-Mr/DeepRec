{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from metric import precision_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ITEM = 4698 + 1\n",
    "MAX_SEQ_LENGTH = 200      # Max sequence length\n",
    "MIN_SEQ_LENGTH = 20       # Min sequence length\n",
    "EMBEDDING_DIM = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#User: 7499\t#Item: 4698\n",
      "796479 49833\n"
     ]
    }
   ],
   "source": [
    "from data import Dataset\n",
    "\n",
    "data = Dataset(csvfile='interactions.csv', \n",
    "               num_test_users=500, \n",
    "               sample=0.15, \n",
    "               cut_item=100)\n",
    "\n",
    "train, test = data.get_train_test_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_prob = np.ones(MAX_ITEM)\n",
    "pop_list = data.train.item.value_counts()\n",
    "pop_prob[pop_list.index] = pop_list.values\n",
    "pop_prob = np.log1p(pop_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[161, 190, 222, 313, 422, 534, 152, 456, 488, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1041, 2177, 1750, 1929, 4569, 4457, 4448, 366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1041, 1750, 2177, 464, 1489, 1720, 1937, 3148...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                      item_sequence\n",
       "0     1  [161, 190, 222, 313, 422, 534, 152, 456, 488, ...\n",
       "1     2  [1041, 2177, 1750, 1929, 4569, 4457, 4448, 366...\n",
       "2     3  [1041, 1750, 2177, 464, 1489, 1720, 1937, 3148..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item_sequence</th>\n",
       "      <th>eval_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>[248, 158, 1041, 201, 1, 532, 2933, 364, 478, ...</td>\n",
       "      <td>[1282, 4302, 408, 4202, 4028, 4092, 815, 2402,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>[139, 319, 36, 486, 460, 128, 478, 1181, 3522,...</td>\n",
       "      <td>[4333, 500, 512, 3414, 1349, 2889, 4392, 146, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>[796, 282, 389, 644, 751, 1231, 280, 993, 1154...</td>\n",
       "      <td>[1793, 1908, 2601, 1010, 992]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                      item_sequence  \\\n",
       "0    39  [248, 158, 1041, 201, 1, 532, 2933, 364, 478, ...   \n",
       "1    59  [139, 319, 36, 486, 460, 128, 478, 1181, 3522,...   \n",
       "2    66  [796, 282, 389, 644, 751, 1231, 280, 993, 1154...   \n",
       "\n",
       "                                       eval_sequence  \n",
       "0  [1282, 4302, 408, 4202, 4028, 4092, 815, 2402,...  \n",
       "1  [4333, 500, 512, 3414, 1349, 2889, 4392, 146, ...  \n",
       "2                      [1793, 1908, 2601, 1010, 992]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sequence_utils import sliding_windows, pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MiniBatcher():\n",
    "    \"\"\"\n",
    "    Create mini batch for df (dataframe of sequences).\n",
    "    \n",
    "    First sliding windows (long sequences would be cut into several pices). Then, zero padding to the left.\n",
    "    \n",
    "    While iterate the dataset, sequences would be shuffled. And negative items would be generated.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, n_items, \n",
    "                 batch_size=128, \n",
    "                 shuffle=True,\n",
    "                 random_state=None):\n",
    "        \n",
    "        self._n_items = n_items\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if random_state is None:\n",
    "            random_state = np.random.RandomState(123)\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Gen sequence\n",
    "        sequences = self._gen_sequences(df, maxlen=MAX_SEQ_LENGTH, minlen=MIN_SEQ_LENGTH)\n",
    "        user_ids, sequences = zip(*sequences)   # It's memory-consuming, but faster to gen mini batch.\n",
    "        self.user_ids = user_ids\n",
    "        # Pad zeros\n",
    "        self.sequences = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH)\n",
    "        self._size = len(self.sequences)\n",
    "        \n",
    "    def _gen_sequences(self, df, shuffle=True, maxlen=200, minlen=20):\n",
    "        \"\"\"\n",
    "        Generate sequences.\n",
    "        If too long, divide it into multiple slice; \n",
    "        If too short, drop it.\n",
    "        \n",
    "        Return a generator: tuple (user, sequence)\n",
    "        \"\"\"\n",
    "        for row in df.itertuples():\n",
    "            uid, seq = row[1], row[2]\n",
    "\n",
    "            # Skip short sequence\n",
    "            if len(seq) < minlen: \n",
    "                continue\n",
    "\n",
    "            for sub in sliding_windows(seq, window_size=maxlen, \n",
    "                                        step_size=maxlen):\n",
    "                yield uid, sub\n",
    "\n",
    "    def _get_negative_items(self, shape, prob=None):\n",
    "        if prob is None:\n",
    "            prob = np.ones(self._n_items)\n",
    "        assert(len(prob) == self._n_items)\n",
    "        \n",
    "        prob /= prob.sum()\n",
    "\n",
    "        negative_items = self.random_state.choice(np.arange(self._n_items),  p=prob,\n",
    "                                                  size=shape)\n",
    "        return negative_items\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterate the whole dataset per mini-batch.\n",
    "        \"\"\"\n",
    "        indices = np.arange(self._size)\n",
    "        # Shuffle indices\n",
    "        if self.shuffle:\n",
    "            self.random_state.shuffle(indices)\n",
    "        # Generate negative items\n",
    "        negative_items = self._get_negative_items(shape=(self._size, MAX_SEQ_LENGTH), \n",
    "                                                  prob=pop_prob)\n",
    "        # per mini batch\n",
    "        for i in range(0, self._size, self.batch_size):\n",
    "            batch_indices = indices[i : i + self.batch_size]\n",
    "            \n",
    "            yield self.sequences[batch_indices], negative_items[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from spotlight.layers import ScaledEmbedding, ZeroEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=32,\n",
    "                       item_embedding_layer=None, sparse=False):\n",
    "\n",
    "        super(GRUNet, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        if item_embedding_layer is not None:\n",
    "            self.item_embeddings = item_embedding_layer\n",
    "        else:\n",
    "            self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                                   padding_idx=0,\n",
    "                                                   sparse=sparse)\n",
    "\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1, sparse=sparse,\n",
    "                                         padding_idx=0)\n",
    "        \n",
    "        self.constant_pad = nn.ConstantPad1d(padding=(1,0), value=0)\n",
    "        \n",
    "        # RNN layer\n",
    "        self.gru = nn.GRU(batch_first=True,\n",
    "                        input_size=embedding_dim,\n",
    "                        hidden_size=embedding_dim)\n",
    "        \n",
    "        # Multi-layer perceptron (fully-connected layers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(embedding_dim*2, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(embedding_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def user_representation(self, sequences):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            sequences: 2D (batch, length)\n",
    "        \n",
    "        Return:\n",
    "            tuple: 3D (batch, length, embedding_dim), 3D (batch, 1, embedding_dim)\n",
    "        \"\"\"\n",
    "        # pad a zero\n",
    "        sequences = self.constant_pad(sequences) # (batch_size, length + 1)\n",
    "        \n",
    "        # Embedding sequences\n",
    "        emb_seq = self.item_embeddings(sequences)\n",
    "        \n",
    "        # User representation\n",
    "        user_repr, _ = self.gru(emb_seq)      # (batch_size, seq_len, embedding_dim)\n",
    "        user_final = user_repr[:, -1:, :]        # Get final representation (batch_size, 1, embedding_dim)\n",
    "\n",
    "        return user_repr[:, :-1, :], user_final\n",
    "    \n",
    "    def forward(self, user_representations, targets):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            user_representations: 3D (batch_size, length, embedding_dim)\n",
    "\n",
    "            targets: 2D (batch_size, length)\n",
    "        \n",
    "        Return:\n",
    "            prediction score: 2D (batch, length)\n",
    "        \"\"\"\n",
    "        # Targets\n",
    "        target_bias = self.item_biases(targets).squeeze()\n",
    "        emb_target = self.item_embeddings(targets)  # (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # Score\n",
    "#         x = torch.cat([user_representations, emb_target], dim=-1)\n",
    "#         out = self.mlp(x).squeeze()\n",
    "        out = (user_representations * emb_target).sum(-1).squeeze()\n",
    "        \n",
    "        return out + target_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (conv 1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal CNN for sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_items, embedding_dim=32, num_layers=1, sparse=False):\n",
    "\n",
    "        super(SeqCNN, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                               padding_idx=0,\n",
    "                                               sparse=sparse)\n",
    "\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1, sparse=sparse,\n",
    "                                         padding_idx=0)\n",
    "        \n",
    "        # Convolution layers\n",
    "        self.kernel_size = k = 3\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = [\n",
    "            nn.Conv1d(embedding_dim,  # Cin\n",
    "                      embedding_dim,  # Cout\n",
    "                      kernel_size=k) \n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "            \n",
    "        self.conv = nn.Conv1d(embedding_dim,  # Cin\n",
    "                              embedding_dim,  # Cout\n",
    "                              kernel_size=k)\n",
    "        \n",
    "    def user_representation(self, sequences):\n",
    "        emb_seq = self.item_embeddings(sequences)  # (N, L, E)\n",
    "        emb_seq = emb_seq.permute(0, 2, 1)         # (N, E, L), embedding_dim is the channels\n",
    "        \n",
    "        x = F.pad(emb_seq,                # (N, E, k + L)\n",
    "                  (self.kernel_size, 0))\n",
    "        x = F.tanh(self.convs[0](x))      # (N, E, 1 + L)\n",
    "        \n",
    "        # Residual\n",
    "        x = x + F.pad(emb_seq, (1, 0))    # (N, E, 1 + L)\n",
    "        \n",
    "        # Rest layers\n",
    "        for i in range(1, self.num_layers):\n",
    "            residual = x\n",
    "            x = F.pad(x, (self.kernel_size - 1, 0))\n",
    "            x = F.tanh(self.convs[i](x))\n",
    "            x = x + residual\n",
    "        \n",
    "        return x[:,:,:-1], x[:,:,-1:]     # (N, E, L),  (N, E, 1)\n",
    "        \n",
    "    def forward(self, user_representation, targets):\n",
    "        \"\"\"\n",
    "        user_representation: (N, E, L)\n",
    "        targets: (N, L)\n",
    "        \"\"\"\n",
    "        emb_target = self.item_embeddings(targets).permute(0,2,1) # (N, E, L)\n",
    "        \n",
    "        b_i = self.item_biases(targets).squeeze()  # (N, L)\n",
    "        \n",
    "        dot = (user_representation * emb_target).sum(1).squeeze() # (N, L)\n",
    "        return dot + b_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (conv 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2dCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal CNN for sequences (2d conv).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_items, embedding_dim=32, sparse=False):\n",
    "\n",
    "        super(Seq2dCNN, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.item_embeddings = ScaledEmbedding(num_items, embedding_dim,\n",
    "                                               padding_idx=0,\n",
    "                                               sparse=sparse)\n",
    "        self.item_biases = ZeroEmbedding(num_items, 1, sparse=sparse,\n",
    "                                         padding_idx=0)\n",
    "        \n",
    "        # Convolution layers\n",
    "        self.kernel_size = k = 3\n",
    "        self.conv = nn.Conv2d(embedding_dim,  # Cin\n",
    "                               embedding_dim,  # Cout\n",
    "                               kernel_size=(k,1))\n",
    "        \n",
    "    def user_representation(self, sequences):\n",
    "        emb_seq = self.item_embeddings(sequences)  # (N, L, E)\n",
    "        emb_seq = emb_seq.permute(0, 2, 1)         # (N, E, L), embedding_dim is the channels\n",
    "        emb_seq = emb_seq.unsqueeze(3)             # (N, E, L, 1)\n",
    "        \n",
    "        x = F.pad(emb_seq,                # (N, E, k + L, 1)\n",
    "                  (0, 0, self.kernel_size, 0))\n",
    "        x = F.tanh(self.conv(x))          # (N, E, 1 + L, 1)\n",
    "        \n",
    "        # Residual\n",
    "        x = x + F.pad(emb_seq, (0, 0, 1, 0))    # (N, E, 1 + L, 1)\n",
    "        x = x.squeeze(3)\n",
    "        \n",
    "        return x[:,:,:-1], x[:,:,-1:]     # (N, E, L),  (N, E, 1)\n",
    "        \n",
    "    def forward(self, user_representation, targets):\n",
    "        \"\"\"\n",
    "        user_representation: (N, E, L)\n",
    "        targets: (N, L)\n",
    "        \"\"\"\n",
    "        emb_target = self.item_embeddings(targets).permute(0,2,1) # (N, E, L)\n",
    "        \n",
    "        b_i   = self.item_biases(targets).squeeze()  # (N, L)\n",
    "        \n",
    "        dot = (user_representation * emb_target).sum(1).squeeze() # (N, L)\n",
    "        return dot + b_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(net, sequences, item_ids=None):\n",
    "    \"\"\"\n",
    "    net: model\n",
    "    sequences: 2D array\n",
    "    item_ids: 2D array\n",
    "    \"\"\"\n",
    "    # Set to test mode (will not dropout or batch norm)\n",
    "    net.train(False)\n",
    "    \n",
    "    sequences = np.atleast_2d(sequences)\n",
    "    \n",
    "    if item_ids is None:\n",
    "        item_ids = np.atleast_2d(np.arange(MAX_ITEM))\n",
    "        item_ids = item_ids.repeat(len(sequences), axis=0)\n",
    "    else:\n",
    "        item_ids = np.atleast_2d(item_ids)\n",
    "        assert(len(sequences) == len(item_ids))\n",
    "    \n",
    "    n_items = item_ids.shape[1]\n",
    "    \n",
    "    # To tensor\n",
    "    sequences = torch.from_numpy(sequences.astype('int64'))\n",
    "    item_ids = torch.from_numpy(item_ids.astype('int64'))\n",
    "    \n",
    "    # To variable\n",
    "    sequence_var = Variable(sequences)\n",
    "    item_var = Variable(item_ids)\n",
    "    \n",
    "    # Get user representation\n",
    "    _, user_final = net.user_representation(sequence_var)\n",
    "    \n",
    "    shape = list(user_final.size())  # (N, E, 1)\n",
    "    shape[2] = n_items\n",
    "    user_final = user_final.expand(shape)  # (N, E, L)\n",
    "    \n",
    "    # Prediction\n",
    "    out = net(user_final, item_var)\n",
    "    \n",
    "    return out.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bpr_loss(positive_predictions, negative_predictions, mask=None):\n",
    "    \"\"\"\n",
    "    Bayesian Personalised Ranking [1]_ pairwise loss function.\n",
    "    \"\"\"\n",
    "    loss = (1.0 - F.sigmoid(positive_predictions -\n",
    "                            negative_predictions))\n",
    "    #     loss = -F.logsigmoid(negative_predictions -\n",
    "    #                          positive_predictions)\n",
    "    if mask is not None:\n",
    "        mask = mask.float()\n",
    "        loss = loss * mask\n",
    "        return loss.sum() / mask.sum()\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "def hinge_loss(positive_predictions, negative_predictions):\n",
    "    \"\"\"\n",
    "    Hinge pairwise loss function.\n",
    "    \"\"\"\n",
    "    loss = torch.clamp(negative_predictions -\n",
    "                       positive_predictions +\n",
    "                       1.0, 0.0)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "test_sequences = pad_sequences(test.item_sequence, maxlen=MAX_SEQ_LENGTH)\n",
    "eval_sequences = test.eval_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(_net, sequences, eval_sequences):\n",
    "    output = predict(_net, sequences)\n",
    "    topk_recs = np.argsort(-output)[:, :20]\n",
    "    return precision_recall(topk_recs, eval_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_LAYERS = 1\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "L2_NORM = 1e-5\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "random_state = np.random.RandomState(123)\n",
    "\n",
    "seed = random_state.randint(-10**8, 10**8)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Data\n",
    "batcher = MiniBatcher(train, MAX_ITEM, \n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      shuffle=True,\n",
    "                      random_state=random_state)\n",
    "\n",
    "# Model\n",
    "_net = SeqCNN(num_items=MAX_ITEM,\n",
    "              embedding_dim=EMBEDDING_DIM,\n",
    "              num_layers=NUM_LAYERS)\n",
    "# Optim\n",
    "optimizer = optim.Adam(_net.parameters(),\n",
    "                        weight_decay=L2_NORM,\n",
    "                        lr=LEARNING_RATE)\n",
    "# Loss function\n",
    "loss_function = bpr_loss\n",
    "\n",
    "# Iteration\n",
    "for i in range(1, EPOCHS+1):\n",
    "    _net.train(True)\n",
    "    epoch_loss = 0.0\n",
    "    start = time()\n",
    "\n",
    "    # Batch training\n",
    "    for j, (batch_seq, batch_neg) in enumerate(batcher):  # __iter__\n",
    "        # Input\n",
    "        sequences_var     = Variable(torch.from_numpy(batch_seq.astype('int64')))\n",
    "        neg_sequences_var = Variable(torch.from_numpy(batch_neg.astype('int64')))\n",
    "        mask = sequences_var > 0\n",
    "        \n",
    "        # Sequence representations\n",
    "        user_repr, _ = _net.user_representation(sequences_var)\n",
    "        \n",
    "        # Score\n",
    "        positive_pred = _net(user_repr, sequences_var)\n",
    "        negative_pred = _net(user_repr, neg_sequences_var)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Loss\n",
    "        loss = loss_function(positive_pred, negative_pred, mask)\n",
    "        epoch_loss += loss.data[0]\n",
    "        \n",
    "        # Backward & update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"#Epoch {0} \\tLoss: {1:.4f} \\t{2:.1f}s\".format(i, epoch_loss/(j+1), time()-start))\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        p,r,DCG = evaluate(_net, test_sequences, eval_sequences)\n",
    "        print(\"\\tPre@20: {0:.2f}%  Rec@20: {1:.2f}%  NDCG@20: {2:.4f}\".format(p*100, r*100, DCG))\n",
    "    \n",
    "print(\"Done training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "\n",
    "class MySequenceModel(ImplicitSequenceModel):\n",
    "    \n",
    "    def predict(self, sequences, item_ids=None):\n",
    "        self._net.train(False)\n",
    "\n",
    "        sequences = np.atleast_2d(sequences)\n",
    "\n",
    "        if item_ids is None:\n",
    "            item_ids = np.arange(self._num_items).reshape(-1, 1)\n",
    "\n",
    "        sequences = torch.from_numpy(sequences.astype(np.int64).reshape(1, -1))\n",
    "        item_ids = torch.from_numpy(item_ids.astype(np.int64))\n",
    "\n",
    "        sequence_var = Variable(sequences)\n",
    "        item_var = Variable(item_ids)\n",
    "\n",
    "        _, sequence_representations = self._net.user_representation(sequence_var)\n",
    "        \n",
    "        size = (len(item_var), ) + sequence_representations.size()[1:]\n",
    "        out = self._net(sequence_representations.expand(*size),\n",
    "                        item_var)\n",
    "\n",
    "        return out.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.2682572480902743\n",
      "Epoch 1: loss 0.18318165972161649\n",
      "Epoch 2: loss 0.16311376197124594\n",
      "Epoch 3: loss 0.1521787647880725\n",
      "Epoch 4: loss 0.1466848581139721\n",
      "Epoch 5: loss 0.1427982431739124\n",
      "Epoch 6: loss 0.14100971161874373\n",
      "Epoch 7: loss 0.13974539735423985\n",
      "Epoch 8: loss 0.14023387976991597\n",
      "Epoch 9: loss 0.13828193407450148\n",
      "Epoch 10: loss 0.1369533599979842\n",
      "Epoch 11: loss 0.13618914293709086\n",
      "Epoch 12: loss 0.1361529262208227\n",
      "Epoch 13: loss 0.13653984265540964\n",
      "Epoch 14: loss 0.13587565353112435\n"
     ]
    }
   ],
   "source": [
    "from spotlight.interactions import SequenceInteractions\n",
    "\n",
    "batcher = MiniBatcher(train, MAX_ITEM, batch_size=128)\n",
    "train_seq = SequenceInteractions(num_items=MAX_ITEM, \n",
    "                                 sequences=batcher.sequences, \n",
    "                                 user_ids=batcher.user_ids)\n",
    "\n",
    "model = MySequenceModel(n_iter=15,\n",
    "                        batch_size=128,\n",
    "                        learning_rate=1e-2,\n",
    "                        l2=1e-5,\n",
    "                        random_state=np.random.RandomState(123),\n",
    "                        representation='cnn',\n",
    "                        loss='bpr')\n",
    "\n",
    "model._num_items = train_seq.num_items\n",
    "model._net = SeqCNN(MAX_ITEM, EMBEDDING_DIM)\n",
    "model._optimizer = optim.Adam(\n",
    "                model._net.parameters(),\n",
    "                weight_decay=model._l2,\n",
    "                lr=model._learning_rate)\n",
    "model._loss_func = bpr_loss\n",
    "\n",
    "model.fit(train_seq, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "test_seq = _pad_sequences(test.item_sequence, maxlen=MAX_SEQ_LENGTH)\n",
    "\n",
    "predictions = np.zeros((len(test_seq), MAX_ITEM))\n",
    "for i, seq in enumerate(test_seq):\n",
    "    predictions[i] = model.predict(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3272, 3522, 3393, ...,  158, 3475, 2173],\n",
       "       [ 139,  158, 3393, ...,  514, 1041,  509],\n",
       "       [3522, 2950, 3396, ..., 2869, 1910, 3393],\n",
       "       ..., \n",
       "       [ 520, 1181,  158, ..., 1041, 1540, 1937],\n",
       "       [3090, 2617, 2364, ..., 1638, 3525, 1705],\n",
       "       [3522, 3919, 4339, ..., 3148, 4201, 3393]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_recs = np.argsort(-predictions)[:, :20]\n",
    "topk_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@20: 5.28%  Recall@20: 10.35%  NDCG@20: 0.3684\n"
     ]
    }
   ],
   "source": [
    "p, r, DCG = precision_recall(topk_recs, test.eval_sequence)\n",
    "print(\"Precision@20: {0:.2f}%  Recall@20: {1:.2f}%  NDCG@20: {2:.4f}\".format(p*100, r*100, DCG))\n",
    "# Precision@20: 4.70%  Recall@20: 9.21%\n",
    "# Precision@20: 6.11%  Recall@20: 12.27%\n",
    "\n",
    "# Precision@20: 4.79%  Recall@20: 8.30%  NDCG@20: 0.3414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@20: 3.62%  Recall@20: 8.15%  NDCG@20: 0.2597\n"
     ]
    }
   ],
   "source": [
    "popk_items = data.train.item.value_counts().sort_values(ascending=False)[:20].index.values\n",
    "\n",
    "n_test = len(test.item_sequence)\n",
    "popk_items = popk_items.reshape(1,-1).repeat(n_test, axis=0)\n",
    "\n",
    "p, r, DCG = precision_recall(popk_items, test.eval_sequence)\n",
    "print(\"Precision@20: {0:.2f}%  Recall@20: {1:.2f}%  NDCG@20: {2:.4f}\".format(p*100, r*100, DCG))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
