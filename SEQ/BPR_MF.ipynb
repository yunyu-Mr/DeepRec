{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from spotlight.layers import ScaledEmbedding, ZeroEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randstate = np.random.RandomState(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#User: 7499\t#Item: 4698\n",
      "796479 49833\n"
     ]
    }
   ],
   "source": [
    "from data import Dataset\n",
    "\n",
    "data = Dataset(csvfile='interactions.csv', \n",
    "               num_test_users=500, \n",
    "               sample=0.15, \n",
    "               cut_item=100)\n",
    "\n",
    "train = data.train_plus\n",
    "test  = data.test_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_USERS = 7499 + 1\n",
    "N_ITEMS = 4698 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69314718,  7.69848279,  6.50578406, ...,  2.39789527,\n",
       "        3.98898405,  3.91202301])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_prob = np.ones(N_ITEMS)\n",
    "pop_list = train.item.value_counts()\n",
    "pop_prob[pop_list.index] = pop_list.values\n",
    "pop_prob = np.log1p(pop_prob)\n",
    "pop_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import utils as skutils\n",
    "\n",
    "class Interactions():\n",
    "    def __init__(self, df, meta=None, shuffle=True):\n",
    "        self.users = df.user.values.astype('int64')\n",
    "        self.items = df.item.values.astype('int64')\n",
    "        \n",
    "        self.size = len(df)\n",
    "        \n",
    "        self.n_users = df.user.unique().size\n",
    "        self.n_items = df.item.unique().size\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def batch_generator(self, batch_size, randstate):\n",
    "        if randstate is None:\n",
    "            randstate = np.random.RandomState(123)\n",
    "            \n",
    "        idx = np.arange(self.size)\n",
    "        if self.shuffle:\n",
    "            idx = skutils.shuffle(idx, \n",
    "                                  random_state=randstate)\n",
    "        for i in range(0, len(idx), batch_size):\n",
    "            b = idx[i : i + batch_size]\n",
    "            batch = {\n",
    "                'users': torch.from_numpy(self.users[b].astype('int64')),\n",
    "                'items': torch.from_numpy(self.items[b].astype('int64'))\n",
    "            }\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFNet(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=32):\n",
    "        super(MFNet, self).__init__()\n",
    "        \n",
    "        self.user_embedding = ScaledEmbedding(n_users, embedding_dim)\n",
    "        self.item_embedding = ScaledEmbedding(n_items, embedding_dim)\n",
    "        \n",
    "        self.user_bias = ZeroEmbedding(n_users, 1)\n",
    "        self.item_bias = ZeroEmbedding(n_items, 1)\n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        emb_user = self.user_embedding(user_ids).squeeze()\n",
    "        emb_item = self.item_embedding(item_ids).squeeze()\n",
    "        \n",
    "        out = (emb_user * emb_item).sum(-1).squeeze()\n",
    "        \n",
    "        b_u = self.user_bias(user_ids).squeeze()\n",
    "        b_i = self.item_bias(item_ids).squeeze()\n",
    "        \n",
    "        return out + b_u + b_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImplicitModel():\n",
    "    def __init__(self, n_users, n_items, embedding_dim=32, \n",
    "                 optimizer=None, loss_function=None, \n",
    "                 lr=1e-3, \n",
    "                 l2=1e-5, \n",
    "                 randstate=None):\n",
    "        \n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        if randstate is None:\n",
    "            randstate = np.random.RandomState(123)\n",
    "        self.randstate = randstate\n",
    "        \n",
    "        # Model\n",
    "        self._net = MFNet(n_users, \n",
    "                          n_items, \n",
    "                          embedding_dim)\n",
    "        # Adam default\n",
    "        if optimizer is None:\n",
    "            optimizer = optim.Adam(self._net.parameters(), \n",
    "                                   lr=lr, \n",
    "                                   weight_decay=l2)\n",
    "        self._optimizer = optimizer\n",
    "        \n",
    "        # Loss function\n",
    "        if loss_function is None:\n",
    "            loss_function = bpr_loss\n",
    "        self._loss_function = loss_function\n",
    "        \n",
    "    def fit(self, train, epochs=10, batch_size=128, verbose=True):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            train: Interactions\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(1, epochs+1):\n",
    "            epoch_loss = 0.0\n",
    "            start = time()\n",
    "            \n",
    "            batcher = train.batch_generator(batch_size, randstate)\n",
    "            for j, batch in enumerate(batcher):\n",
    "                items_var = Variable(batch['items'])\n",
    "                users_var = Variable(batch['users'])\n",
    "                \n",
    "                # Predict\n",
    "                pred = self._net(users_var, items_var)\n",
    "                \n",
    "                neg_pred = self._get_negative_prediction(users_var)\n",
    "                \n",
    "                self._optimizer.zero_grad()\n",
    "                \n",
    "                # Loss\n",
    "                loss = self._loss_function(pred, neg_pred)\n",
    "                epoch_loss += loss.data[0]\n",
    "                \n",
    "                # Update\n",
    "                loss.backward()\n",
    "                self._optimizer.step()\n",
    "                \n",
    "            if verbose:    \n",
    "                print(\"#Epoch {0} \\tLoss: {1:.4f}\\t {2:.1f}s\".format(i, epoch_loss /(j+1), time()-start))\n",
    "        print(\"Done training!\")\n",
    "        \n",
    "    def _get_negative_prediction(self, users_var):\n",
    "        items = np.arange(self.n_items)\n",
    "        # Random choice\n",
    "#         p = pop_prob / pop_prob.sum()\n",
    "        neg_items = self.randstate.choice(items, #p=p,\n",
    "                                          size=users_var.size()[0])\n",
    "        # To tensor\n",
    "        neg_items = torch.from_numpy(neg_items.astype('int64'))\n",
    "        neg_var = Variable(neg_items)\n",
    "        \n",
    "        # Predict\n",
    "        return self._net(users_var, neg_var)\n",
    "    \n",
    "    \n",
    "    def predict(self, user_ids, item_ids=None):\n",
    "        self._net.train(False)\n",
    "\n",
    "        user_ids = user_ids.reshape(-1, 1)  # 1D to 2D (batch_size, 1)\n",
    "\n",
    "        if item_ids is None:\n",
    "            item_ids = np.arange(N_ITEMS)\n",
    "            item_ids = np.atleast_2d(item_ids)                 #          (1, n_items)\n",
    "            item_ids = item_ids.repeat(len(user_ids), axis=0)  # (batch_size, n_items)\n",
    "        else:\n",
    "            assert(len(user_ids) == len(item_ids))\n",
    "\n",
    "        # To tensor\n",
    "        user_ids = torch.from_numpy(user_ids.astype('int64'))\n",
    "        item_ids = torch.from_numpy(item_ids.astype('int64'))\n",
    "        # To variable\n",
    "        user_var = Variable(user_ids)\n",
    "        item_var = Variable(item_ids)\n",
    "\n",
    "        # Repeat vector\n",
    "        user_var = user_var.expand_as(item_var) # (batch_size, n_items)\n",
    "\n",
    "        # Predict\n",
    "        predictions = self._net(user_var, item_var)\n",
    "\n",
    "        return predictions.data.numpy()\n",
    "    \n",
    "    def predict_by_batch(self, user_ids, item_ids=None, batch_size=1000):\n",
    "        preds = []\n",
    "        for i in range(0, len(user_ids), batch_size):\n",
    "            pred = self.predict(user_ids[i : i+batch_size], item_ids=item_ids)\n",
    "            preds.append(pred)\n",
    "        return np.vstack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bpr_loss(positive_pred, negative_pred):\n",
    "    loss = 1.0 - F.sigmoid(positive_pred - negative_pred)\n",
    "    return loss.mean()\n",
    "\n",
    "def hinge_loss(positive_pred, negative_pred):\n",
    "    loss = F.relu(negative_pred - positive_pred + 1.0)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = Interactions(train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImplicitModel(N_USERS, N_ITEMS, embedding_dim=32,\n",
    "                      loss_function=bpr_loss, \n",
    "                      lr=1e-2,\n",
    "                      l2=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 1 \tLoss: 0.3377\t 3.6s\n",
      "#Epoch 2 \tLoss: 0.2168\t 3.6s\n",
      "#Epoch 3 \tLoss: 0.2104\t 3.5s\n",
      "#Epoch 4 \tLoss: 0.2060\t 3.5s\n",
      "#Epoch 5 \tLoss: 0.2044\t 3.5s\n",
      "#Epoch 6 \tLoss: 0.2033\t 3.5s\n",
      "#Epoch 7 \tLoss: 0.2026\t 3.5s\n",
      "#Epoch 8 \tLoss: 0.2014\t 3.5s\n",
      "#Epoch 9 \tLoss: 0.2008\t 3.6s\n",
      "#Epoch 10 \tLoss: 0.2009\t 3.5s\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "model.fit(dtrain, epochs=15, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from metric import precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test item lists sorted by user.\n",
    "test_lists = test.groupby('user').agg({\n",
    "    'item': lambda x:list(x)\n",
    "})['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre@20: 3.78% \tRec@20: 8.29% \tNDCG@20: 0.2644\n"
     ]
    }
   ],
   "source": [
    "N_TOP = 20\n",
    "\n",
    "# Test user ids.\n",
    "test_users = np.sort(test.user.unique())\n",
    "# Prediction for each user.\n",
    "pred = model.predict_by_batch(test_users)\n",
    "\n",
    "# Get topk and sorted\n",
    "topk = np.argpartition(-pred, kth=np.arange(N_TOP))[:, :N_TOP]  \n",
    "\n",
    "n_test = len(test_lists)\n",
    "p, r, DCG = precision_recall(topk, test_lists)\n",
    "print(\"Pre@20: {0:.2f}% \\tRec@20: {1:.2f}% \\tNDCG@20: {2:.4f}\".format(p*100, r*100, DCG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1041, 3662,  139, 3148, 1181,  158, 1750, 2177,  128, 1929,  114,\n",
       "         248,  220,  319, 3522,  464,  462, 3393,   36, 1139]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "pop_list = train.item.value_counts().index.values\n",
    "topk = pop_list[:k]\n",
    "topk = np.atleast_2d(topk)\n",
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre@20: 3.62%  Rec@20: 8.15%  NDCG@20: 0.2596\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_lists)\n",
    "p, r, DCG = precision_recall(topk.repeat(n_test, axis=0), test_lists)\n",
    "print(\"Pre@20: {0:.2f}%  Rec@20: {1:.2f}%  NDCG@20: {2:.4f}\".format(p*100, r*100, DCG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
